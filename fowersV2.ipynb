{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP88T/rmM/SUzj8uj6J5DKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-nazli/mobileNet_model_training/blob/main/fowersV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFvef7qMT80P",
        "outputId": "3b71ad5d-5a94-4a56-89c2-5b223b59dd9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import json, random, os\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "ZPDblyAQUU9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir   = \"/content/drive/MyDrive/staj\"\n",
        "tgz_path   = f\"{data_dir}/102flowers.tgz\"\n",
        "labels_path= f\"{data_dir}/imagelabels.mat\"\n",
        "label_map_path = \"/content/label_map.json\""
      ],
      "metadata": {
        "id": "p9DYGo8BUYXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!tar -xzf \"$tgz_path\" -C /content/\n",
        "print(\"total picture:\", len(os.listdir(\"/content/jpg\")))"
      ],
      "metadata": {
        "id": "OEE-MIE5Gafa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(label_map_path) as f:\n",
        "    label_map = json.load(f)"
      ],
      "metadata": {
        "id": "Eylod-7gUtud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json, shutil, scipy.io\n",
        "from pathlib import Path\n",
        "\n",
        "IMAGES_DIR = Path(\"/content/jpg\")\n",
        "LABELS_MAT = \"/content/drive/MyDrive/staj/imagelabels.mat\"\n",
        "LABEL_MAP  = \"/content/label_map.json\"\n",
        "\n",
        "\n",
        "labels_mat = scipy.io.loadmat(LABELS_MAT)[\"labels\"][0]\n",
        "with open(LABEL_MAP) as f:\n",
        "    id2name = json.load(f)\n",
        "\n",
        "\n",
        "DATA_DIR = Path(\"/content/data_species_named\")\n",
        "if DATA_DIR.exists(): shutil.rmtree(DATA_DIR)\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "for k in range(1, 103):\n",
        "    (DATA_DIR / id2name[str(k)].replace(\" \", \"_\")).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "for i, cls_id in enumerate(labels_mat, start=1):\n",
        "    fname = f\"image_{i:05d}.jpg\"\n",
        "    dst   = DATA_DIR / id2name[str(int(cls_id))].replace(\" \", \"_\") / fname\n",
        "    shutil.copy(IMAGES_DIR / fname, dst)\n",
        "\n",
        "print(\"The pictures were divided into folders:\", DATA_DIR)\n"
      ],
      "metadata": {
        "id": "qmSjoLzrGhsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os, json\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "\n",
        "\n",
        "def setup_gpu():\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            print(\" GPU memory growth enabled\")\n",
        "        except:\n",
        "            print(\" GPU error\")\n",
        "\n",
        "setup_gpu()\n",
        "\n",
        "\n",
        "class Config:\n",
        "    DATA_DIR = \"/content/data_species_named\"\n",
        "    LABEL_MAP_PATH = \"/content/label_map.json\"\n",
        "    IMG_SIZE = (224, 224)\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS_STAGE1 = 20\n",
        "    EPOCHS_STAGE2 = 15\n",
        "    SEED = 42\n",
        "\n",
        "\n",
        "    LR_STAGE1 = 1e-3\n",
        "    LR_STAGE2 = 1e-5\n",
        "\n",
        "\n",
        "    WEAK_CLASSES = [\n",
        "        \"sweet_pea\", \"mallow\", \"petunia\", \"pink_primrose\",\n",
        "        \"desert-rose\", \"yellow_iris\", \"lotus\", \"water_lily\"\n",
        "    ]\n",
        "\n",
        "config = Config()\n",
        "\n",
        "\n",
        "def load_class_names_from_labelmap(label_map_path):\n",
        "    with open(label_map_path, \"r\") as f:\n",
        "        id2name = json.load(f)\n",
        "    return [id2name[str(i)] for i in range(1, len(id2name)+1)]\n",
        "\n",
        "\n",
        "def create_datasets():\n",
        "    print(\"Dataset loading...\")\n",
        "\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        config.DATA_DIR,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=config.SEED,\n",
        "        image_size=config.IMG_SIZE,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        label_mode='int'\n",
        "    )\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        config.DATA_DIR,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=config.SEED,\n",
        "        image_size=config.IMG_SIZE,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        label_mode='int'\n",
        "    )\n",
        "\n",
        "    class_names = load_class_names_from_labelmap(config.LABEL_MAP_PATH)\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    print(f\" Total classes: {num_classes}\")\n",
        "    print(f\"Weak classes: {len(config.WEAK_CLASSES)}\")\n",
        "\n",
        "    return train_ds, val_ds, class_names, num_classes\n",
        "\n",
        "#augmentation\n",
        "def create_augmentation_layers():\n",
        "    normal_aug = tf.keras.Sequential([\n",
        "        RandomFlip(\"horizontal\"),\n",
        "        RandomRotation(0.15),\n",
        "        RandomZoom(0.15),\n",
        "        RandomContrast(0.15),\n",
        "        RandomBrightness(0.1),\n",
        "    ])\n",
        "\n",
        "    strong_aug = tf.keras.Sequential([\n",
        "        RandomFlip(\"horizontal_and_vertical\"),\n",
        "        RandomRotation(0.25),\n",
        "        RandomZoom(0.25),\n",
        "        RandomContrast(0.25),\n",
        "        RandomBrightness(0.2),\n",
        "        RandomTranslation(0.1, 0.1),\n",
        "    ])\n",
        "\n",
        "    return normal_aug, strong_aug\n",
        "\n",
        "def smart_augment(images, labels, weak_indices, normal_aug, strong_aug):\n",
        "    def augment_one(inputs):\n",
        "        image, label = inputs\n",
        "        is_weak = tf.reduce_any(tf.equal(label, weak_indices))\n",
        "\n",
        "        def weak_aug():\n",
        "            return tf.cond(\n",
        "                tf.random.uniform([]) < 0.7,\n",
        "                lambda: strong_aug(tf.expand_dims(image, 0))[0],\n",
        "                lambda: normal_aug(tf.expand_dims(image, 0))[0]\n",
        "            )\n",
        "\n",
        "        def normal():\n",
        "            return normal_aug(tf.expand_dims(image, 0))[0]\n",
        "\n",
        "        return tf.cond(is_weak, weak_aug, normal)\n",
        "\n",
        "    augmented_images = tf.map_fn(\n",
        "        augment_one,\n",
        "        (images, labels),\n",
        "        fn_output_signature=tf.float32\n",
        "    )\n",
        "\n",
        "    return augmented_images, labels\n",
        "\n",
        "\n",
        "def create_balanced_dataset(train_ds, class_names):\n",
        "    print(\"The balanced dataset is being created...\")\n",
        "\n",
        "    normal_aug, strong_aug = create_augmentation_layers()\n",
        "    weak_indices = tf.constant([class_names.index(c) for c in config.WEAK_CLASSES if c in class_names], dtype=tf.int32)\n",
        "\n",
        "    def augment_fn(images, labels):\n",
        "        return smart_augment(images, labels, weak_indices, normal_aug, strong_aug)\n",
        "\n",
        "    augmented_ds = train_ds.map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    weak_ds = train_ds.filter(lambda x, y: tf.reduce_any(tf.equal(y, weak_indices))).map(\n",
        "        augment_fn, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    final_ds = augmented_ds.concatenate(weak_ds.repeat(3))\n",
        "    return final_ds.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#model\n",
        "def create_mobile_model(num_classes):\n",
        "    print(\" Mobile model is being created...\")\n",
        "\n",
        "    base_model = tf.keras.applications.MobileNetV3Small(\n",
        "        input_shape=config.IMG_SIZE + (3,),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        alpha=1.0,\n",
        "        minimalistic=False,\n",
        "        include_preprocessing=False\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=config.IMG_SIZE + (3,))\n",
        "    x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"MobileFlowerClassifier\")\n",
        "    return model, base_model\n",
        "\n",
        "#focal loss\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def focal_loss_fn(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), tf.shape(y_pred)[1])\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-8, 1.0 - 1e-8)\n",
        "        ce_loss = -y_true * tf.math.log(y_pred)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        focal_weight = alpha * tf.pow(1 - pt, gamma)\n",
        "        focal_loss = focal_weight * ce_loss\n",
        "        return tf.reduce_mean(tf.reduce_sum(focal_loss, axis=1))\n",
        "    return focal_loss_fn\n",
        "\n",
        "#class weight\n",
        "def calculate_class_weights(train_ds, num_classes):\n",
        "    print(\"Class weights is calculated...\")\n",
        "    all_labels = []\n",
        "    for _, labels in train_ds:\n",
        "        all_labels.extend(labels.numpy())\n",
        "    class_weights = compute_class_weight('balanced', classes=np.arange(num_classes), y=all_labels)\n",
        "    return {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "\n",
        "def create_callbacks():\n",
        "    return [\n",
        "        ModelCheckpoint(\"best_mobile_flower_model.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=4, min_lr=1e-7),\n",
        "        TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
        "    ]\n",
        "\n",
        "# training pipeline\n",
        "def train_model():\n",
        "    train_ds, val_ds, class_names, num_classes = create_datasets()\n",
        "    train_balanced = create_balanced_dataset(train_ds, class_names)\n",
        "    val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    model, base_model = create_mobile_model(num_classes)\n",
        "    class_weights = calculate_class_weights(train_ds, num_classes)\n",
        "    callbacks = create_callbacks()\n",
        "\n",
        "    print(\"\\n STAGE 1...\")\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=config.LR_STAGE1),\n",
        "        loss=focal_loss(),\n",
        "        metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5_acc\")]\n",
        "    )\n",
        "    history1 = model.fit(train_balanced, validation_data=val_ds,\n",
        "                         epochs=config.EPOCHS_STAGE1, class_weight=class_weights, callbacks=callbacks)\n",
        "\n",
        "    print(\"\\n STAGE 2...\")\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=config.LR_STAGE2),\n",
        "        loss=focal_loss(gamma=1.5),\n",
        "        metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5_acc\")]\n",
        "    )\n",
        "    history2 = model.fit(train_balanced, validation_data=val_ds,\n",
        "                         epochs=config.EPOCHS_STAGE2, class_weight=class_weights, callbacks=callbacks)\n",
        "    return model, class_names, history1, history2, val_ds\n",
        "\n",
        "\n",
        "def export_for_mobile(model, class_names, val_ds):\n",
        "    print(\"\\n Mobile export...\")\n",
        "    model.save(\"mobile_flower_classifier_full.keras\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "    def representative_data_gen():\n",
        "        for images, _ in val_ds.take(100):\n",
        "            for image in images:\n",
        "                yield [tf.expand_dims(image, 0)]\n",
        "    converter.representative_dataset = representative_data_gen\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    with open(\"mobile_flower_classifier.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    with open(\"class_names.txt\", \"w\") as f:\n",
        "        for name in class_names:\n",
        "            f.write(f\"{name}\\n\")\n",
        "\n",
        "    print(f\"tflite model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")\n",
        "    return tflite_model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\" MOBILE FLOWER CLASSIFIER - PRODUCTION VERSION \")\n",
        "    print(\"=\" * 60)\n",
        "    model, class_names, hist1, hist2, val_ds = train_model()\n",
        "    tflite_model = export_for_mobile(model, class_names, val_ds)\n",
        "    print(\"\\n model was complated\")\n"
      ],
      "metadata": {
        "id": "WEcKtdzVDVTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}